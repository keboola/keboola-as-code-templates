{
  parameters: {
    size: "small",
    autoSuspendAfterSeconds: 1800,
    dataApp: {
      slug: "duckdb-sql-data-app",
      streamlit: {
        "config.toml": '[theme]\nfont = "sans serif"\ntextColor = "#222529"\nbackgroundColor = "#FFFFFF"\nsecondaryBackgroundColor = "#E6F2FF"\nprimaryColor = "#1F8FFF"',
      },
    },
    script: [
      "import streamlit as st\nimport duckdb\nimport pandas as pd\nimport os\nimport time\nimport re\nimport sqlglot\n\n\n# Page configuration\nst.set_page_config(\n    page_title=\"DuckDB SQL Data App\",\n    page_icon=\"ðŸ¦†\",\n    layout=\"wide\"\n)\n\n# Constants\nMAX_QUERY_EXECUTION_TIME = 30  # seconds\nQUERY_PREVIEW_LENGTH = 60  # Characters to show in query preview\nDEFAULT_LIMIT = 100  # Default LIMIT for queries\nDATA_FOLDER = [\"/data/in/files/\", \"/data/in/tables/\"]  # Local data folder for CSV/Parquet files\n\n\ndef convert_to_duckdb(sql: str, debug_mode: bool = False) -\u003e str:\n    \"\"\"\n    Simple Snowflake to DuckDB converter with improved error handling\n    \"\"\"\n    if not sql or not sql.strip():\n        return sql\n    \n    try:\n        # Use sqlglot for Snowflake to DuckDB conversion with enhanced settings\n        converted = sqlglot.transpile(\n            sql, \n            read=\"snowflake\",      # Source: Snowflake SQL dialect\n            write=\"duckdb\",        # Target: DuckDB SQL dialect  \n            pretty=True,           # Format output nicely\n            identify=True,         # Preserve identifier quoting\n            normalize=True         # Normalize SQL structure\n        )\n        \n        # Check if conversion actually happened\n        if not converted or len(converted) == 0:\n            # SQLGlot couldn't parse the query - likely invalid syntax\n            return sql  # Return original to trigger error handling in UI\n        \n        # Ensure each query has a semicolon before joining\n        queries_with_semicolons = []\n        for query in converted:\n            query = query.strip()\n            # Fix common INSERT INTO issues - add missing table name (handle newlines)\n            query = re.sub(r'INSERT\\s+INTO\\s+\\n?\\s*SELECT', 'CREATE TABLE result_table AS\\nSELECT', query, flags=re.IGNORECASE | re.MULTILINE)\n            \n            # Add semicolon if missing\n            if not query.endswith(';'):\n                query = query + ';'\n            queries_with_semicolons.append(query)\n        \n        result = '\\n\\n'.join(queries_with_semicolons)\n        \n        return result\n    except Exception as e:\n        # SQLGlot parsing error - likely invalid Snowflake syntax\n        if debug_mode:\n            return f\"-- Conversion failed: Invalid Snowflake query syntax\\n-- Error: {str(e)}\\n{sql}\"\n        return sql  # Return original to trigger error handling in UI\n\n\ndef get_available_tables(conn) -\u003e list:\n    \"\"\"Get list of available tables in DuckDB\"\"\"\n    try:\n        result = conn.execute(\"SHOW TABLES\").fetchdf()\n        return result['name'].tolist()\n    except Exception as e:\n        # Return empty list on error\n        return []\n\n# Initialize DuckDB\n@st.cache_resource\ndef init_duckdb():\n    return duckdb.connect(':memory:')\n\n\ndef validate_sql_query(query: str) -\u003e tuple[bool, str]:\n    \"\"\"Minimal validation for testing - allow any SQL query.\"\"\"\n    if not query or not query.strip():\n        return False, \"Query cannot be empty\"\n    \n    # No security restrictions for testing version\n    return True, \"\"\n\ndef execute_single_query(conn, query: str) -\u003e dict:\n    \"\"\"\n    Execute a single SQL query with proper error handling and timing.\n    Returns dict with result, error, execution_time, and row_count.\n    \"\"\"\n    start_time = time.time()\n    \n    try:\n        # Validate query first\n        is_valid, error_msg = validate_sql_query(query)\n        if not is_valid:\n            return {\n                'success': False,\n                'error': f\"Validation error: {error_msg}\",\n                'result': None,\n                'execution_time': 0,\n                'row_count': 0\n            }\n        \n        # Execute query - clean version without signal timeout\n        query_clean = query.strip()\n        query_upper = query_clean.upper()\n        \n        # Remove comments and find the actual SQL command\n        # Split by lines and find first non-comment line\n        query_lines = query_upper.split('\\n')\n        actual_command = None\n        for line in query_lines:\n            line_clean = line.strip()\n            if line_clean and not line_clean.startswith('--'):\n                actual_command = line_clean\n                break\n        \n        # If no actual command found, use the full query\n        if not actual_command:\n            actual_command = query_upper.strip()\n        \n        # Check for data-returning queries (SELECT, DESCRIBE, etc.)\n        is_data_query = any(actual_command.startswith(keyword) for keyword in [\n            'SELECT', 'DESCRIBE', 'SHOW', 'EXPLAIN', 'WITH'\n        ])\n        \n        # Check if this is a CREATE TABLE query (including CREATE OR REPLACE TABLE)\n        is_create_table = ('CREATE TABLE' in query_upper or \n                          'CREATE OR REPLACE TABLE' in query_upper)\n        \n        # Execute query with proper handling\n        if is_data_query:\n            # For SELECT-like queries, use fetchdf() - no artificial limit, get all results\n            result = conn.execute(query_clean).fetchdf()\n            has_data = len(result) \u003e 0 and len(result.columns) \u003e 0\n        else:\n            # For CREATE/INSERT/DELETE queries, just execute\n            conn.execute(query_clean)\n            result = None\n            has_data = False\n            \n        execution_time = time.time() - start_time\n        \n        if is_data_query and has_data:\n            \n            return {\n                'success': True,\n                'error': None,\n                'result': result,\n                'execution_time': execution_time,\n                'row_count': len(result)\n            }\n        \n        elif is_data_query and not has_data:\n            # Data query with no results (e.g., SELECT with no matches)\n            return {\n                'success': True,\n                'error': None,\n                'result': result,  # Empty DataFrame\n                'execution_time': execution_time,\n                'row_count': 0\n            }\n        \n        elif is_create_table:\n            try:\n                # Try to extract table name from CREATE TABLE query\n                # Handle CREATE TABLE, CREATE OR REPLACE TABLE, and CREATE TABLE IF NOT EXISTS\n                import re\n                table_match = re.search(r'CREATE\\s+(?:OR\\s+REPLACE\\s+)?TABLE\\s+(?:IF\\s+NOT\\s+EXISTS\\s+)?([`\"\\w\\[\\]]+)', query_clean, re.IGNORECASE)\n                if table_match:\n                    table_name = table_match.group(1).strip('\"`[]')\n                    # Get full preview of the created table (up to 500 rows for performance)\n                    preview_result = conn.execute(f'SELECT * FROM \"{table_name}\" LIMIT 500').fetchdf()\n                    return {\n                        'success': True,\n                        'error': None,\n                        'result': preview_result,\n                        'execution_time': execution_time,\n                        'row_count': len(preview_result),\n                        'message': f\"Table '{table_name}' created successfully\",\n                        'table_created': table_name,\n                        'is_create_table_preview': True\n                    }\n                else:\n                    # Fallback if table name extraction fails\n                    return {\n                        'success': True,\n                        'error': None,\n                        'result': None,\n                        'execution_time': execution_time,\n                        'row_count': 0,\n                        'message': f\"Query executed successfully: CREATE TABLE command completed\"\n                    }\n            except Exception as preview_error:\n                # If preview fails, still return success for the CREATE TABLE\n                return {\n                    'success': True,\n                    'error': None,\n                    'result': None,\n                    'execution_time': execution_time,\n                    'row_count': 0,\n                    'message': f\"Table created successfully (preview unavailable: {str(preview_error)})\"\n                }\n        \n        else:\n            # Non-data query (INSERT, DELETE, etc.)\n            return {\n                'success': True,\n                'error': None,\n                'result': None,\n                'execution_time': execution_time,\n                'row_count': 0,\n                'message': f\"Query executed successfully: {actual_command.split()[0]} command completed\"\n            }\n        \n    except duckdb.Error as e:\n        return {\n            'success': False,\n            'error': f\"DuckDB error: {str(e)}\",\n            'result': None,\n            'execution_time': time.time() - start_time,\n            'row_count': 0\n        }\n    except Exception as e:\n        return {\n            'success': False,\n            'error': f\"Unexpected error: {str(e)}\",\n            'result': None,\n            'execution_time': time.time() - start_time,\n            'row_count': 0\n        }\n\n# Function to convert CSV to Parquet\ndef convert_csv_to_parquet(csv_path, parquet_path):\n    \"\"\"Convert CSV file to Parquet format\"\"\"\n    try:\n        df = pd.read_csv(csv_path)\n        df.to_parquet(parquet_path, index=False)\n        return True, f\"Converted: {os.path.basename(csv_path)} â†’ {os.path.basename(parquet_path)}\"\n    except Exception as e:\n        return False, f\"Error converting {os.path.basename(csv_path)}: {e}\"\n\n# Load and convert files\ndef load_and_convert_tables(force_reload=False):\n    tables = {}\n    conversion_messages = []\n    converted_files = []\n    loaded_files = []\n\n    # Find CSV and Parquet files from all data folders\n    csv_files = []\n    parquet_files = []\n    for folder in DATA_FOLDER:\n        if os.path.exists(folder):\n            csv_files.extend([(f, folder) for f in os.listdir(folder) if f.endswith('.csv')])\n            parquet_files.extend([(f, folder) for f in os.listdir(folder) if f.endswith('.parquet')])\n\n    # Convert CSV to Parquet if needed\n    for csv_file, folder in csv_files:\n        csv_path = os.path.join(folder, csv_file)\n        parquet_file = csv_file.replace('.csv', '.parquet')\n        parquet_path = os.path.join(folder, parquet_file)\n\n        need_conversion = True\n        if os.path.exists(parquet_path) and not force_reload:\n            csv_mtime = os.path.getmtime(csv_path)\n            parquet_mtime = os.path.getmtime(parquet_path)\n            need_conversion = csv_mtime \u003e parquet_mtime\n\n        if need_conversion or force_reload:\n            success, _ = convert_csv_to_parquet(csv_path, parquet_path)\n            if success:\n                table_name = csv_file.replace('.csv', '')\n                converted_files.append(f\"â€“ {table_name}\")\n                if (parquet_file, folder) not in parquet_files:\n                    parquet_files.append((parquet_file, folder))\n\n    # Load Parquet files\n    for parquet_file, folder in parquet_files:\n        parquet_path = os.path.join(folder, parquet_file)\n        if os.path.exists(parquet_path):\n            try:\n                df = pd.read_parquet(parquet_path)\n                table_name = parquet_file.replace('.parquet', '')\n                tables[table_name] = df\n                loaded_files.append(f\"â€“ {table_name}\")\n            except Exception as e:\n                conversion_messages.append(f\"Error loading {parquet_file}: {e}\")\n\n    if loaded_files:\n        conversion_messages.append(\"Loaded\")\n        conversion_messages.extend(loaded_files)\n\n    if converted_files:\n        conversion_messages.append(f\"Converted ({len(converted_files)})\")\n\n    return tables, conversion_messages\n\n# Get sample queries based on available tables\ndef get_sample_queries(tables):\n    \"\"\"Generate sample queries based on available tables with improved logic\"\"\"\n    if not tables:\n        return {}\n    \n    first_table = list(tables.keys())[0]\n    first_df = tables[first_table]\n    \n    # Get column information\n    columns = first_df.columns.tolist()\n    numeric_columns = first_df.select_dtypes(include=['number']).columns.tolist()\n    \n    # Quote table and column names for DuckDB compatibility\n    quoted_table = f'\"{first_table}\"'\n    quoted_columns = [f'\"{col}\"' for col in columns]\n    quoted_numeric_columns = [f'\"{col}\"' for col in numeric_columns]\n    \n    # Create statistics query for numeric columns\n    if numeric_columns:\n        stats_parts = []\n        for col in numeric_columns[:2]:  # Limit to first 2 numeric columns\n            col_name = col  # Plain column name for alias\n            quoted_col = f'\"{col}\"'  # Quoted column name for SQL\n            stats_parts.append(f'AVG({quoted_col}) as avg_{col_name}, MAX({quoted_col}) as max_{col_name}, MIN({quoted_col}) as min_{col_name}')\n        statistics_query = f\"SELECT {', '.join(stats_parts)} FROM {quoted_table};\"\n    else:\n        statistics_query = f\"SELECT COUNT(*) FROM {quoted_table};\"\n    \n    sample_queries = {\n        \"Basic SELECT - First 10 rows\": f\"SELECT * FROM {quoted_table} LIMIT {DEFAULT_LIMIT};\",\n        \"Count all rows\": f\"SELECT COUNT(*) as total_rows FROM {quoted_table};\",\n        \"Show table structure\": f\"DESCRIBE {quoted_table};\",\n        \"First 5 rows with specific columns\": f\"SELECT {', '.join(quoted_columns[:3])} FROM {quoted_table} LIMIT 5;\" if len(columns) \u003e= 3 else f\"SELECT * FROM {quoted_table} LIMIT 5;\",\n        \"Group by first column\": f\"SELECT {quoted_columns[0]}, COUNT(*) as count FROM {quoted_table} GROUP BY {quoted_columns[0]} ORDER BY count DESC LIMIT {DEFAULT_LIMIT};\" if columns else f\"SELECT * FROM {quoted_table} LIMIT {DEFAULT_LIMIT};\",\n        \"Statistics for numeric columns\": statistics_query,\n        \"Distinct values in first column\": f\"SELECT DISTINCT {quoted_columns[0]} FROM {quoted_table} ORDER BY {quoted_columns[0]} LIMIT 20;\" if columns else f\"SELECT * FROM {quoted_table} LIMIT {DEFAULT_LIMIT};\",\n        \"Random sample\": f\"SELECT * FROM {quoted_table} ORDER BY RANDOM() LIMIT 50;\",\n        \"Latest records (if timestamp exists)\": f\"SELECT * FROM {quoted_table} ORDER BY {quoted_columns[0]} DESC LIMIT {DEFAULT_LIMIT};\" if columns else f\"SELECT * FROM {quoted_table} LIMIT {DEFAULT_LIMIT};\",\n        \"Join multiple tables\": _generate_join_query(tables, first_table, columns) if len(tables) \u003e 1 else f\"SELECT * FROM {quoted_table} LIMIT {DEFAULT_LIMIT};\"\n    }\n    \n    return sample_queries\n\ndef _generate_join_query(tables, first_table, first_columns):\n    \"\"\"Generate a smart JOIN query between tables with proper DuckDB quoting.\"\"\"\n    if len(tables) \u003c 2 or not first_columns:\n        return f'SELECT * FROM \"{first_table}\" LIMIT {DEFAULT_LIMIT};'\n    \n    second_table = list(tables.keys())[1]\n    second_columns = list(tables[second_table].columns)\n    \n    # Try to find common column names for JOIN\n    common_columns = set(first_columns).intersection(set(second_columns))\n    join_column = list(common_columns)[0] if common_columns else first_columns[0]\n    \n    return f'SELECT * FROM \"{first_table}\" a JOIN \"{second_table}\" b ON a.\"{join_column}\" = b.\"{join_column}\" LIMIT {DEFAULT_LIMIT};'\n\n# Simplified logging - no complex debugging needed\n\ndef _display_query_result(query_number: int, query_text: str, result: dict):\n    \"\"\"Display the result of a single query execution\"\"\"\n    \n    if result['success']:\n        # Determine if this was a data-returning query or not\n        has_data = result['result'] is not None\n        message = result.get('message', '')\n        is_create_table_preview = result.get('is_create_table_preview', False)\n        table_created = result.get('table_created', '')\n        \n        if has_data:\n            # Success case with data (SELECT, DESCRIBE, CREATE TABLE with preview, etc.)\n            if is_create_table_preview:\n                # Special display for CREATE TABLE with preview\n                with st.expander(f\"Query {query_number} - Table '{table_created}' Created - Preview ({result['row_count']:,} rows) ({result['execution_time']:.3f}s)\", expanded=True):\n                    # Show the executed query\n                    st.code(query_text, language=\"sql\")\n                    \n                    # Success message\n                    st.success(message)\n                    \n                    # Results metrics\n                    col1, col2, col3 = st.columns(3)\n                    with col1:\n                        st.metric(\"Preview Rows\", f\"{result['row_count']:,}\")\n                    with col2:\n                        st.metric(\"Columns\", len(result['result'].columns))\n                    with col3:\n                        st.metric(\"Execution Time\", f\"{result['execution_time']:.3f}s\")\n\n                    # Display data preview\n                    if result['result'].empty:\n                        st.info(\"Table created but contains no data (0 rows)\")\n                        st.dataframe(result['result'], use_container_width=True, hide_index=True)\n                    else:\n                        st.subheader(f\"Table Content ({len(result['result'])} rows shown)\")\n                        st.dataframe(result['result'], use_container_width=True, hide_index=True)\n\n                    # Download buttons for the preview data\n                    if not result['result'].empty:\n                        col_d1, col_d2 = st.columns(2)\n                        with col_d1:\n                            csv_data = result['result'].to_csv(index=False)\n                            st.download_button(\n                                \"Download as CSV\", \n                                csv_data, \n                                f\"table_{table_created}.csv\", \n                                \"text/csv\", \n                                use_container_width=True\n                            )\n                        with col_d2:\n                            parquet_data = result['result'].to_parquet(index=False)\n                            st.download_button(\n                                \"Download as Parquet\", \n                                parquet_data, \n                                f\"table_{table_created}.parquet\", \n                                \"application/octet-stream\", \n                                use_container_width=True\n                            )\n            else:\n                # Regular data query (SELECT, DESCRIBE, etc.)\n                with st.expander(f\"Query {query_number} Results - {result['row_count']:,} rows ({result['execution_time']:.3f}s)\", expanded=True):\n                    # Show the executed query\n                    st.code(query_text, language=\"sql\")\n                    \n                    # Results metrics\n                    col1, col2, col3 = st.columns(3)\n                    with col1:\n                        st.metric(\"Rows\", f\"{result['row_count']:,}\")\n                    with col2:\n                        st.metric(\"Columns\", len(result['result'].columns))\n                    with col3:\n                        st.metric(\"Execution Time\", f\"{result['execution_time']:.3f}s\")\n\n                    # Display results\n                    if result['result'].empty:\n                        st.info(\"No data returned by the query (0 rows)\")\n                        st.dataframe(result['result'], use_container_width=True, hide_index=True)\n                    else:\n                        st.dataframe(result['result'], use_container_width=True, hide_index=True)\n\n                    # Download buttons\n                    col_d1, col_d2 = st.columns(2)\n                    with col_d1:\n                        csv_data = result['result'].to_csv(index=False)\n                        st.download_button(\n                            \"Download as CSV\", \n                            csv_data, \n                            f\"query_result_{query_number}.csv\", \n                            \"text/csv\", \n                            use_container_width=True\n                        )\n                    with col_d2:\n                        parquet_data = result['result'].to_parquet(index=False)\n                        st.download_button(\n                            \"Download as Parquet\", \n                            parquet_data, \n                            f\"query_result_{query_number}.parquet\", \n                            \"application/octet-stream\", \n                            use_container_width=True\n                        )\n        else:\n            # Success case without data (INSERT, DELETE, etc.)\n            with st.expander(f\"Query {query_number} Executed - {result['execution_time']:.3f}s\", expanded=True):\n                # Show the executed query\n                st.code(query_text, language=\"sql\")\n                \n                # Success message\n                if message:\n                    st.success(message)\n                else:\n                    st.success(\"Query executed successfully!\")\n                \n                # Execution time metric\n                col1, col2, col3 = st.columns(3)\n                with col1:\n                    st.metric(\"Status\", \"Success\")\n                with col2:\n                    st.metric(\"Execution Time\", f\"{result['execution_time']:.3f}s\")\n                with col3:\n                    st.metric(\"Type\", \"Non-data query\")\n    else:\n        # Error case\n        with st.expander(f\"Query {query_number} - Error\", expanded=True):\n            st.error(f\"Query failed: {result['error']}\")\n            st.info(\"Check SQL syntax, table names, and permissions\")\n            st.code(query_text, language=\"sql\")\n            \n            if result['execution_time'] \u003e 0:\n                st.caption(f\"Failed after {result['execution_time']:.3f}s\")\n\n# Note: Example usage code removed to save memory in production environment\n\n# ðŸ¦† DuckDB SQL Data App Sidebar\nst.sidebar.title(\"ðŸ¦† DuckDB SQL Data App\")\n\n# Load and convert data (no manual reload button)\ntables, _ = load_and_convert_tables(force_reload=False)\nconn = init_duckdb()\n\n# Register tables in DuckDB\nfor name, df in tables.items():\n    try:\n        conn.register(name, df)\n    except Exception as e:\n        st.sidebar.error(f\"Failed to register table {name}: {e}\")\n\n# Menu\npage = st.sidebar.selectbox(\"Navigation\", [\"Tables List\", \"Snowflake â†’ DuckDB\", \"DuckDB SQL editor\"])\n\n# List of available tables with expandable info\nif tables:\n    st.sidebar.subheader(\"Available Tables\")\n    for name, df in tables.items():\n        with st.sidebar.expander(f\"{name} ({len(df)} rows)\"):\n            # Basic table info\n            st.markdown(f\"**Number of rows:** {len(df)}\")\n            st.markdown(f\"**Columns ({len(df.columns)}):**\")\n            st.write(list(df.columns))\n#             st.markdown(\"**First 5 rows:**\")\n#             st.dataframe(df.head(5))\nelse:\n    st.sidebar.warning(f\"No files in data folders: {', '.join(DATA_FOLDER)}\")\n    st.sidebar.info(\"Supported formats: CSV, Parquet\")\n    st.sidebar.info(\"Create 'data' folder and add files\")\n\n# PAGE 1: Tables List\nif page == \"Tables List\":\n    st.title(\"Tables List\")\n    \n    if not tables:\n        st.warning(f\"Create data folders ({', '.join(DATA_FOLDER)}) and add CSV or Parquet files\")\n        st.info(\"CSV files will be automatically converted to Parquet for better performance\")\n    else:\n        # Top container - tables overview in 3x3 grid\n        st.subheader(\"Available Tables\")\n        \n        # Initialize selected table in session state\n        if \"selected_table\" not in st.session_state:\n            st.session_state.selected_table = None\n        \n        # Initialize page state for pagination\n        if \"table_page\" not in st.session_state:\n            st.session_state.table_page = 0\n        \n        # Display tables in 3x3 grid with pagination\n        table_list = list(tables.items())\n        tables_per_page = 9  # 3x3 grid\n        total_pages = (len(table_list) + tables_per_page - 1) // tables_per_page  # Ceiling division\n        \n        # Show pagination info if more than one page\n        if total_pages \u003e 1:\n            col_info, col_nav = st.columns([2, 1])\n            with col_info:\n                st.caption(f\"Showing page {st.session_state.table_page + 1} of {total_pages} ({len(table_list)} tables total)\")\n            with col_nav:\n                # Navigation buttons\n                nav_col1, nav_col2 = st.columns(2)\n                with nav_col1:\n                    if st.button(\"Previous\", disabled=st.session_state.table_page == 0):\n                        st.session_state.table_page = max(0, st.session_state.table_page - 1)\n                        st.rerun()\n                with nav_col2:\n                    if st.button(\"Next\", disabled=st.session_state.table_page \u003e= total_pages - 1):\n                        st.session_state.table_page = min(total_pages - 1, st.session_state.table_page + 1)\n                        st.rerun()\n        \n        # Get tables for current page\n        page_start = st.session_state.table_page * tables_per_page\n        page_end = min(page_start + tables_per_page, len(table_list))\n        page_tables = table_list[page_start:page_end]\n        \n        # Create 3x3 grid container with fixed height\n        with st.container():\n            # Create 3 rows of 3 columns each\n            for row in range(3):\n                if row * 3 \u003c len(page_tables):\n                    cols = st.columns(3)\n                    \n                    for col_idx in range(3):\n                        table_idx = row * 3 + col_idx\n                        \n                        if table_idx \u003c len(page_tables):\n                            name, df = page_tables[table_idx]\n                            \n                            with cols[col_idx]:\n                                # Create clickable container for each table\n                                with st.container():\n                                    # Use button to make container clickable - only table name\n                                    if st.button(\n                                        f\"**{name}**\", \n                                        key=f\"table_btn_{name}\",\n                                        use_container_width=True,\n                                        type=\"secondary\" if st.session_state.selected_table != name else \"primary\"\n                                    ):\n                                        st.session_state.selected_table = name\n                                        st.rerun()\n                        else:\n                            # Empty placeholder for grid alignment\n                            with cols[col_idx]:\n                                st.empty()\n        \n        st.divider()\n        \n        # Bottom container - table preview\n        st.subheader(\"Table Preview\")\n        \n        # Show selected table or prompt to select\n        if st.session_state.selected_table and st.session_state.selected_table in tables:\n            selected = st.session_state.selected_table\n            df = tables[selected]\n            \n            # Display selected table name\n            st.markdown(f\"**Selected Table:** `{selected}`\")\n            \n            # Statistics\n            col1, col2, col3, col4 = st.columns(4)\n            with col1:\n                st.metric(\"Rows\", f\"{len(df):,}\")\n            with col2:\n                st.metric(\"Columns\", len(df.columns))\n            with col3:\n                memory_usage = df.memory_usage(deep=True).sum() / (1024 * 1024)\n                st.metric(\"Memory\", f\"{memory_usage:.2f} MB\")\n            with col4:\n                # Try to find parquet file in any of the data folders\n                parquet_path = None\n                for folder in DATA_FOLDER:\n                    test_path = os.path.join(folder, f\"{selected}.parquet\")\n                    if os.path.exists(test_path):\n                        parquet_path = test_path\n                        break\n                if parquet_path and os.path.exists(parquet_path):\n                    file_size = os.path.getsize(parquet_path) / (1024 * 1024)\n                    st.metric(\"File\", f\"{file_size:.2f} MB\")\n            \n            # Data preview - REMOVED INDEXES\n            df_display = df.copy()\n            st.dataframe(df_display, use_container_width=True, hide_index=True)\n            \n            # Column information\n            with st.expander(\"Column Information\"):\n                col_info = pd.DataFrame({\n                    'Column': df.columns,\n                    'Type': df.dtypes.astype(str),\n                    'Null Values': df.isnull().sum(),\n                    'Unique Values': df.nunique()\n                })\n                st.dataframe(col_info, use_container_width=True, hide_index=True)\n        else:\n            st.info(\"Click on a table above to view its details\")\n\n# PAGE 2: Snowflake â†’ DuckDB converter\nelif page == \"Snowflake â†’ DuckDB\":\n    st.title(\"Snowflake â†’ DuckDB Converter\")\n    st.markdown(\n        \"Enter your Snowflake SQL query and click **Convert** to get DuckDB syntax.\"\n    )\n    \n    # Input field for SQL\n    sql_input = st.text_area(\n        \"Snowflake SQL\", \n        height=200,\n        placeholder='Sample Snowflake SQL query'\n    )\n\n    # Convert button\n    if st.button(\"Convert\"):\n        if not sql_input.strip():\n            st.error(\"Please enter a valid Snowflake SQL query.\")\n        else:\n            try:\n                converted = convert_to_duckdb(sql_input, debug_mode=True)\n                \n                # Check if conversion was successful or if original query was returned due to error\n                if converted == sql_input:\n                    st.error(\"Invalid Snowflake query? Please check your SQL syntax and try again.\")\n                    st.info(\"Make sure your query uses valid Snowflake SQL syntax.\")\n                else:\n                    st.subheader(\"DuckDB query\")\n                    st.code(converted, language=\"sql\")\n                    \n            except Exception as e:\n                st.error(\"Invalid Snowflake query? Conversion failed.\")\n                st.error(f\"Error details: {str(e)}\")\n                st.info(\"Please verify your Snowflake SQL syntax and try again.\")\n\n# PAGE 3: DuckDB SQL editor\nelif page == \"DuckDB SQL editor\":  \n    st.title(\"DuckDB SQL editorðŸ¦†\")\n\n    if not tables:\n        st.warning(\"Please load tables first\")\n        st.info(f\"Add CSV or Parquet files to data folders: {', '.join(DATA_FOLDER)}\")\n    else:\n        # Sample Queries Dropdown - moved below editor as requested\n        st.write(\"#### Sample DuckDB query library\")\n        sample_queries = get_sample_queries(tables)\n        \n        # Create expander for sample queries\n        with st.expander(\"Choose from 10 sample queries\", expanded=False):\n            selected_sample = st.selectbox(\n                \"Select a sample query to load into editor:\",\n                options=list(sample_queries.keys()),\n                key=\"sample_selector\"\n            )\n            \n            col_sample1, col_sample2 = st.columns([3, 1])\n            with col_sample2:\n                if st.button(\"Apply sample query\", type=\"secondary\", use_container_width=True):\n                    st.session_state.sql_query = sample_queries[selected_sample]\n                    st.rerun()\n            \n            with col_sample1:\n                if selected_sample:\n                    st.code(sample_queries[selected_sample], language=\"sql\")\n\n        # Initialize session state for query\n        if \"sql_query\" not in st.session_state:\n            st.session_state.sql_query = \"\"  # Start with empty editor\n        \n        sql_query = st.text_area(\n            \"Query:\",\n            value=st.session_state.sql_query,\n            height=150,\n            help=\"Enter SQL query for DuckDB\",\n            key=\"sql_editor\"\n        )\n        \n        # Update session state when query changes\n        st.session_state.sql_query = sql_query\n        \n        # Parse queries for execution\n        queries_preview = [q.strip() for q in sql_query.split(';') if q.strip()]\n        \n        # Initialize session state for query selector visibility\n        if \"show_query_selector\" not in st.session_state:\n            st.session_state.show_query_selector = False\n        \n        # Execute buttons\n        col_exec1, col_exec2, col_exec3, col_exec4 = st.columns([1.5, 1.5, 0.7, 1])\n        \n        with col_exec1:\n            execute_all_btn = st.button(\"ðŸ¦† Execute Query\", type=\"primary\", use_container_width=True)\n        \n        with col_exec2:\n            if len(queries_preview) \u003e 1:\n                execute_selected_btn = st.button(\"ðŸ¦† Execute Selected Query\", type=\"secondary\", use_container_width=True)\n            else:\n                execute_selected_btn = False\n        \n        with col_exec3:\n            if st.button(\"Stop\", use_container_width=True):\n                st.session_state[\"abort_queries\"] = True\n                st.rerun()\n        \n        with col_exec4:\n            if st.button(\"Reset\", type=\"secondary\", use_container_width=True):\n                st.session_state.sql_query = \"\"\n                st.session_state.show_query_selector = False\n                st.rerun()\n        \n        # Show query selector when \"Execute Selected Query\" is clicked\n        if execute_selected_btn:\n            st.session_state.show_query_selector = True\n            st.rerun()\n        \n        # Query Selector - show only when requested\n        selected_queries = []\n        if st.session_state.show_query_selector and len(queries_preview) \u003e 1:\n            st.divider()\n            st.subheader(\"Query Selector\")\n            st.write(\"Select which queries to execute:\")\n            \n            # Create checkboxes for each query\n            for i, query in enumerate(queries_preview):\n                # Show first N characters of query for preview  \n                query_preview = query[:QUERY_PREVIEW_LENGTH] + \"...\" if len(query) \u003e QUERY_PREVIEW_LENGTH else query\n                query_preview = query_preview.replace('\\n', ' ').strip()\n                \n                # Clean the full query for tooltip display\n                query_tooltip = query.strip()\n                \n                is_selected = st.checkbox(\n                    f\"Query {i+1}: {query_preview}\",\n                    value=True,  # Default all selected\n                    key=f\"query_select_{i}\",\n                    help=f\"Complete query:\\n\\n{query_tooltip}\"  # Hover tooltip with full query\n                )\n                \n                if is_selected:\n                    selected_queries.append((i, query))\n            \n            # Execute button for selected queries\n            col_exec_sel1, col_exec_sel2 = st.columns([2, 1])\n            with col_exec_sel1:\n                execute_selected_final_btn = st.button(f\"ðŸ¦† Run Selected Queries ({len(selected_queries)})\", type=\"primary\", use_container_width=True)\n            with col_exec_sel2:\n                if st.button(\"Cancel Selection\", use_container_width=True):\n                    st.session_state.show_query_selector = False\n                    st.rerun()\n        else:\n            execute_selected_final_btn = False\n\n        # Execute queries with improved logic\n        \n        # Execute All Queries button logic\n        if execute_all_btn and queries_preview:\n            st.session_state[\"abort_queries\"] = False  # Reset abort flag\n            st.session_state.show_query_selector = False  # Hide selector when executing all\n\n            with st.spinner(\"ðŸ¦† Processing all queries...\"):\n                # Collect all results first\n                all_results = []\n                \n                for query_index, query_text in enumerate(queries_preview):\n                    if st.session_state.get(\"abort_queries\"):\n                        st.warning(\"Execution stopped by user.\")\n                        break\n\n                    # Execute single query with new function\n                    query_result = execute_single_query(conn, query_text)\n                    all_results.append((query_index + 1, query_text, query_result))\n                \n                # Display all results in correct order (descending)\n                for query_number, query_text, query_result in reversed(all_results):\n                    _display_query_result(query_number, query_text, query_result)\n\n        # Execute Selected Queries button logic\n        elif execute_selected_final_btn and selected_queries:\n            st.session_state[\"abort_queries\"] = False  # Reset abort flag\n            st.session_state.show_query_selector = False  # Hide selector after execution\n\n            with st.spinner(\"ðŸ¦† Processing selected queries...\"):\n                # Collect all results first\n                selected_results = []\n                \n                for query_index, query_text in selected_queries:\n                    if st.session_state.get(\"abort_queries\"):\n                        st.warning(\"Execution stopped by user.\")\n                        break\n\n                    # Execute single query with new function\n                    query_result = execute_single_query(conn, query_text)\n                    selected_results.append((query_index + 1, query_text, query_result))\n                \n                # Display all results in correct order (descending)\n                for query_number, query_text, query_result in reversed(selected_results):\n                    _display_query_result(query_number, query_text, query_result)\n\n        elif execute_selected_final_btn and not selected_queries:\n            st.warning(\"No queries selected for execution. Please select at least one query.\")\n        \n        elif execute_all_btn and not queries_preview:\n            st.warning(\"No queries found. Please enter a SQL query.\")\n\n# Fallback for unknown pages\nelse:\n    st.error(f\"Unsupported page: {page}\")\n\n# Footer\nst.sidebar.markdown(\"---\")\nst.sidebar.markdown(\"**DuckDB SQL Data App**\")\nst.sidebar.caption(f\"Data folders: {', '.join(DATA_FOLDER)}\")\nst.sidebar.markdown(\"*DuckDB Analytics Platform*\")",
    ],
    packages: [
      "duckdb",
      "sqlglot",
    ],
  },
  authorization: {
    app_proxy: {
      auth_providers: [
        {
          id: "simpleAuth",
          type: "password",
        },
      ],
      auth_rules: [
        {
          type: "pathPrefix",
          value: "/",
          auth_required: true,
          auth: [
            "simpleAuth",
          ],
        },
      ],
    },
  },
  storage: {
    input: {
      files: [],
      tables: [],
    },
  },
}
